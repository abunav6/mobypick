{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc7259dc-84c7-4521-b667-392375c3c628",
   "metadata": {},
   "source": [
    "<h1>Moby Pick</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd65cd57-c08e-4464-b7d9-1d152cfff5a4",
   "metadata": {},
   "source": [
    "This notebook uses the CSV files found in the following collection of datasets: https://mengtingwan.github.io/data/goodreads.html and converts them into a format that we can use in our Moby Pick book recommendation engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbd4e633-c8dd-44d8-b1a2-d37190104192",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import itertools\n",
    "from operator import add\n",
    "from csv import reader\n",
    "from itertools import chain\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql.functions import col, expr, udf, collect_list, struct, array, lit, array_max, when\n",
    "from pyspark.sql.types import FloatType, StringType, ArrayType, IntegerType, StructType, StructField, LongType\n",
    "\n",
    "#from polyglot.detect import Detector\n",
    "from langdetect import detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c05a9f35-fd95-474c-b8fd-9a5d3150509c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/12/12 19:41:40 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "23/12/12 19:41:41 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "cf = SparkConf()\n",
    "cf.set(\"spark.submit.deployMode\",\"client\")\n",
    "sc = SparkContext.getOrCreate(cf)\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession \\\n",
    "\t    .builder \\\n",
    "\t    .appName(\"Python Spark SQL basic example\") \\\n",
    "\t    .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "\t    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f68d1cd-8128-4fd0-8e54-6962ef32b34b",
   "metadata": {},
   "source": [
    "First we import the 'works' dataset, which is \"the abstract version of a book regardless any particular editions\" per the dataset descriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3ef850c-733d-4568-9937-8fbc92aa3f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#path = \"../goodreads_book_genres_initial.json\"\n",
    "path = \"./Datasets/goodreads_book_works.json\"\n",
    "bookDF = spark.read.json(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b46e62-9322-4095-9c8b-3a7edd118d77",
   "metadata": {},
   "source": [
    "best_book_id corresponds to the book ID in the reviews dataset, the book ID in the genres dataset, and the book ID in the books dataset so that's what we'll use as the primary identifier for a row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87ce0c73-9cfd-456c-a4de-52d7af25fb8b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3:>                                                          (0 + 5) / 5]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+--------------------------+---------------------------------+----------+--------------------+------------------------+--------------------------+-------------------------+--------------------+--------------------+-------------+-----------+-------------+------------------+--------+\n",
      "|best_book_id|books_count|default_chaptering_book_id|default_description_language_code|media_type|original_language_id|original_publication_day|original_publication_month|original_publication_year|      original_title|         rating_dist|ratings_count|ratings_sum|reviews_count|text_reviews_count| work_id|\n",
      "+------------+-----------+--------------------------+---------------------------------+----------+--------------------+------------------------+--------------------------+-------------------------+--------------------+--------------------+-------------+-----------+-------------+------------------+--------+\n",
      "|    17310087|          1|                          |                                 |      book|                    |                      18|                         9|                     2001|Harry Potter and ...|5:43|4:18|3:5|2:3...|           69|        308|          207|                 4|23970668|\n",
      "+------------+-----------+--------------------------+---------------------------------+----------+--------------------+------------------------+--------------------------+-------------------------+--------------------+--------------------+-------------+-----------+-------------+------------------+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#bookDF.printSchema()\n",
    "#bookDF.show(10)\n",
    "bookDF.filter(bookDF.best_book_id == 17310087).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7392fc-af3d-4cf4-a5d3-c28f6c6c3510",
   "metadata": {},
   "source": [
    "First filter the data so we aren't getting anything that isn't books (e.g. the dataset includes audiobooks and some other media)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5173b0f6-7d9f-4317-9e15-4d6b069f2e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "bookDF = bookDF.filter(col('original_title') != '').filter(col('media_type') == 'book')\n",
    "#bookDF.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd98c6a2-4b87-46e8-8414-bbc64d6a00fa",
   "metadata": {},
   "source": [
    "We only want the books that have gotten the most interactions / are the most popular. We order by the number of ratings the book has had as a proxy value for how popular a book is. Then we limit the dataset to 2000 books, since it's so large."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0634693-7b14-436c-92d3-60797a5f1863",
   "metadata": {},
   "outputs": [],
   "source": [
    "bookDF = bookDF.orderBy(bookDF.ratings_count.cast(\"int\"), ascending=False).limit(2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a62e33c-e68b-494c-b98a-397f0269de75",
   "metadata": {},
   "source": [
    "Take a look and make sure we still have the most popular books in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68eec9a7-0487-4dfc-81ca-bfa2b9c3e810",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 4:>                                                        (0 + 10) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------------------------+--------------------+--------------------+-------------+-------------+--------+\n",
      "|best_book_id|original_publication_year|      original_title|         rating_dist|ratings_count|reviews_count| work_id|\n",
      "+------------+-------------------------+--------------------+--------------------+-------------+-------------+--------+\n",
      "|           3|                     1997|Harry Potter and ...|5:3131920|4:11907...|      4972886|      5801988| 4640799|\n",
      "|           5|                     1999|Harry Potter and ...|5:1303937|4:51915...|      2019176|      2496720| 2402163|\n",
      "|       15881|                     1998|Harry Potter and ...|5:1097387|4:56060...|      1955144|      2431183| 6231171|\n",
      "|           6|                     2000|Harry Potter and ...|5:1227707|4:50391...|      1912948|      2375359| 3046572|\n",
      "|      136251|                     2007|Harry Potter and ...|5:1351479|4:39082...|      1889600|      2383409| 2963218|\n",
      "|           2|                     2003|Harry Potter and ...|5:1149382|4:50233...|      1875594|      2331984| 2809203|\n",
      "|           1|                     2005|Harry Potter and ...|5:1190925|4:46657...|      1824878|      2291161|41335427|\n",
      "|    29056083|                     2016|Harry Potter and ...|5:122849|4:140352...|       423043|       791754|48765776|\n",
      "|      862041|                     1998|Complete Harry Po...|5:167342|4:31173|...|       208105|       272069| 2962492|\n",
      "|       19330|                     1986|The Complete Tale...|5:32990|4:15574|3...|        58324|        69353| 1139913|\n",
      "+------------+-------------------------+--------------------+--------------------+-------------+-------------+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "bookDF.filter(col(\"original_title\").like(\"%Potter%\")).select('best_book_id',\\\n",
    "            'original_publication_year',\\\n",
    "            'original_title',\\\n",
    "            'rating_dist',\\\n",
    "            'ratings_count',\\\n",
    "            'reviews_count',\\\n",
    "            'work_id'\n",
    "           ).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0607c4c3-1a47-4781-9887-d423ab1f2faa",
   "metadata": {},
   "source": [
    "Get the average rating in addition to the distribution, count, and sum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b80b76a-d55a-4bf8-8d3b-72fab199b0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "bookDF = bookDF.select('best_book_id',\\\n",
    "            'original_publication_day',\\\n",
    "            'original_publication_month',\\\n",
    "            'original_publication_year',\\\n",
    "            'original_title',\\\n",
    "            'rating_dist',\\\n",
    "            'ratings_count',\\\n",
    "            'ratings_sum',\\\n",
    "            'reviews_count',\\\n",
    "            'text_reviews_count',\\\n",
    "            'work_id'\n",
    "           ).withColumn(\"avg_rating\", col(\"ratings_sum\") / col(\"ratings_count\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a2abf8-f2d4-427e-8a73-87ed6216c042",
   "metadata": {},
   "source": [
    "<h4>Language</h4>\n",
    "\n",
    "None of the rows in the dataset have an entry for `default_description_language_code`. Because we need language in order to create recommendations for users, we need to fill in a language somehow. We create a UDF to detect the language from the title and use a python package called `langdetect`. There's no need to check the language in the dataset before filling, because again they're all null."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b12399e-0578-465b-986e-6d9d1f49c4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_language(title):\n",
    "    try:\n",
    "        inf_lang = detect(title)\n",
    "        return inf_lang\n",
    "    except Exception as e:\n",
    "        return ''\n",
    "\n",
    "lang_udf = udf(get_language, StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e2a52c2d-9d18-46f9-addb-6de00d657e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "bookDFLanguages = bookDF.withColumn('inferred_language_id', lang_udf(bookDF.original_title))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87c0c79-f22c-4002-b20b-7d738fa3f563",
   "metadata": {},
   "source": [
    "<h4>Genre</h4>\n",
    "\n",
    "Genre is in a separate CSV, so we import it as another dataframe. The genre CSV has a struct type for the genres field. We'll do processing to select the \"best-fit\" genre, indicated by the key in the struct with the highest value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80fbc875-8356-496d-92b9-f0df7e812606",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# join in the genres information\n",
    "pathG = \"./Datasets/goodreads_book_genres_initial.json\"\n",
    "genreDF = spark.read.json(pathG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a8c16bc3-099b-4bad-b7a7-5f5c508a7a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- book_id: string (nullable = true)\n",
      " |-- genres: struct (nullable = true)\n",
      " |    |-- children: long (nullable = true)\n",
      " |    |-- comics, graphic: long (nullable = true)\n",
      " |    |-- fantasy, paranormal: long (nullable = true)\n",
      " |    |-- fiction: long (nullable = true)\n",
      " |    |-- history, historical fiction, biography: long (nullable = true)\n",
      " |    |-- mystery, thriller, crime: long (nullable = true)\n",
      " |    |-- non-fiction: long (nullable = true)\n",
      " |    |-- poetry: long (nullable = true)\n",
      " |    |-- romance: long (nullable = true)\n",
      " |    |-- young-adult: long (nullable = true)\n",
      "\n",
      "+-------+---------------------------------------------------------+\n",
      "|book_id|genres                                                   |\n",
      "+-------+---------------------------------------------------------+\n",
      "|5333265|{NULL, NULL, NULL, NULL, 1, NULL, NULL, NULL, NULL, NULL}|\n",
      "|1333909|{NULL, NULL, NULL, 219, 5, NULL, NULL, NULL, NULL, NULL} |\n",
      "|7327624|{NULL, NULL, 31, 8, NULL, 1, NULL, 1, NULL, NULL}        |\n",
      "|6066819|{NULL, NULL, NULL, 555, NULL, 10, NULL, NULL, 23, NULL}  |\n",
      "|287140 |{NULL, NULL, NULL, NULL, NULL, NULL, 3, NULL, NULL, NULL}|\n",
      "+-------+---------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "genreDF.printSchema()\n",
    "genreDF.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf914fe1-efa1-4992-91f8-673187df9c51",
   "metadata": {},
   "source": [
    "Since we're selecting the key in the struct with the highest value, we need to 0 the null values in the struct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d5087e65-ce53-4040-bd2a-19d62ef18fa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------------------------------------------------------+----------------------------------+\n",
      "|book_id |genres                                                   |nonull_genres                     |\n",
      "+--------+---------------------------------------------------------+----------------------------------+\n",
      "|5333265 |{NULL, NULL, NULL, NULL, 1, NULL, NULL, NULL, NULL, NULL}|{0, 0, 0, 0, 1, 0, 0, 0, 0, 0}    |\n",
      "|1333909 |{NULL, NULL, NULL, 219, 5, NULL, NULL, NULL, NULL, NULL} |{0, 0, 0, 219, 5, 0, 0, 0, 0, 0}  |\n",
      "|7327624 |{NULL, NULL, 31, 8, NULL, 1, NULL, 1, NULL, NULL}        |{0, 0, 31, 8, 0, 1, 0, 1, 0, 0}   |\n",
      "|6066819 |{NULL, NULL, NULL, 555, NULL, 10, NULL, NULL, 23, NULL}  |{0, 0, 0, 555, 0, 10, 0, 0, 23, 0}|\n",
      "|287140  |{NULL, NULL, NULL, NULL, NULL, NULL, 3, NULL, NULL, NULL}|{0, 0, 0, 0, 0, 0, 3, 0, 0, 0}    |\n",
      "|287141  |{6, NULL, 1, 1, 9, NULL, NULL, NULL, NULL, 1}            |{6, 0, 1, 1, 9, 0, 0, 0, 0, 1}    |\n",
      "|378460  |{NULL, NULL, NULL, 2, NULL, NULL, NULL, NULL, NULL, NULL}|{0, 0, 0, 2, 0, 0, 0, 0, 0, 0}    |\n",
      "|6066812 |{16, NULL, 32, 7, NULL, NULL, NULL, NULL, NULL, 8}       |{16, 0, 32, 7, 0, 0, 0, 0, 0, 8}  |\n",
      "|34883016|{NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL, 3, NULL}|{0, 0, 0, 0, 0, 0, 0, 0, 3, 0}    |\n",
      "|287149  |{NULL, NULL, NULL, NULL, 1, NULL, 24, NULL, NULL, NULL}  |{0, 0, 0, 0, 1, 0, 24, 0, 0, 0}   |\n",
      "+--------+---------------------------------------------------------+----------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "genreDF = genreDF.withColumn(\"nonull_genres\", struct(\n",
    "    when(col(\"genres.children\").isNull(), 0).otherwise(col(\"genres.children\")).alias(\"children\"),\n",
    "    when(col(\"genres.`comics, graphic`\").isNull(), 0).otherwise(col(\"genres.`comics, graphic`\")).alias(\"comics, graphic\"),\n",
    "    when(col(\"genres.`fantasy, paranormal`\").isNull(), 0).otherwise(col(\"genres.`fantasy, paranormal`\")).alias(\"fantasy, paranormal\"),\n",
    "    when(col(\"genres.fiction\").isNull(), 0).otherwise(col(\"genres.fiction\")).alias(\"fiction\"),\n",
    "    when(col(\"genres.`history, historical fiction, biography`\").isNull(), 0).otherwise(col(\"genres.`history, historical fiction, biography`\")).alias(\"history, historical fiction, biography\"),\n",
    "    when(col(\"genres.`mystery, thriller, crime`\").isNull(), 0).otherwise(col(\"genres.`mystery, thriller, crime`\")).alias(\"mystery, thriller, crime\"),\n",
    "    when(col(\"genres.`non-fiction`\").isNull(), 0).otherwise(col(\"genres.`non-fiction`\")).alias(\"non-fiction\"),\n",
    "    when(col(\"genres.poetry\").isNull(), 0).otherwise(col(\"genres.poetry\")).alias(\"poetry\"),\n",
    "    when(col(\"genres.romance\").isNull(), 0).otherwise(col(\"genres.romance\")).alias(\"romance\"),\n",
    "    when(col(\"genres.`young-adult`\").isNull(), 0).otherwise(col(\"genres.`young-adult`\")).alias(\"young-adult\")\n",
    "))\n",
    "genreDF.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "25a75419-5e34-448d-996d-bb4475ace2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "genreDF = genreDF.drop(col('genres'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da13df75-2d91-4e1d-acbf-0f657653b3c6",
   "metadata": {},
   "source": [
    "To get the maximum key,value from the struct, we recreate dictionary representation of the struct as a workaround, get the max value, and return the key of that value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "04a0fac2-b31c-416e-9504-bb37bd501dd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------------------------+\n",
      "|book_id |primary_genre                         |\n",
      "+--------+--------------------------------------+\n",
      "|5333265 |history, historical fiction, biography|\n",
      "|1333909 |fiction                               |\n",
      "|7327624 |fantasy, paranormal                   |\n",
      "|6066819 |fiction                               |\n",
      "|287140  |non-fiction                           |\n",
      "|287141  |history, historical fiction, biography|\n",
      "|378460  |fiction                               |\n",
      "|6066812 |fantasy, paranormal                   |\n",
      "|34883016|romance                               |\n",
      "|287149  |non-fiction                           |\n",
      "|6066814 |history, historical fiction, biography|\n",
      "|33394837|mystery, thriller, crime              |\n",
      "|89371   |non-fiction                           |\n",
      "|28575155|children                              |\n",
      "|89373   |fiction                               |\n",
      "+--------+--------------------------------------+\n",
      "only showing top 15 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_max_genre(genre_struct):\n",
    "    # reconstruct the dictionary, beacuse genre_struct.jsonValue()\n",
    "    # wasn't working in udf; pretty small so it shouldn't impact\n",
    "    # performance\n",
    "    children = genre_struct['children']\n",
    "    comics = genre_struct['comics, graphic']\n",
    "    fantasy = genre_struct['fantasy, paranormal']\n",
    "    fiction = genre_struct.fiction\n",
    "    history = genre_struct['history, historical fiction, biography']\n",
    "    mystery = genre_struct['mystery, thriller, crime']\n",
    "    non_fiction = genre_struct['non-fiction']\n",
    "    poetry = genre_struct.poetry\n",
    "    romance = genre_struct.romance\n",
    "    young_adult = genre_struct['young-adult']\n",
    "\n",
    "    # Create a dictionary from the extracted values\n",
    "    genre_dict = {\n",
    "        \"children\": children,\n",
    "        \"comics, graphic\": comics,\n",
    "        \"fantasy, paranormal\": fantasy,\n",
    "        \"fiction\": fiction,\n",
    "        \"history, historical fiction, biography\": history,\n",
    "        \"mystery, thriller, crime\": mystery,\n",
    "        \"non-fiction\": non_fiction,\n",
    "        \"poetry\": poetry,\n",
    "        \"romance\": romance,\n",
    "        \"young-adult\": young_adult\n",
    "    }\n",
    "    return max(genre_dict, key=genre_dict.get)\n",
    "\n",
    "get_max_genres_udf = udf(get_max_genre, StringType())\n",
    "genre_df = genreDF.withColumn('primary_genre', get_max_genres_udf(col('nonull_genres')))\n",
    "genre_df = genre_df.drop('nonull_genres')\n",
    "genre_df.show(15, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433f4eb1-8688-4d99-8a6b-6ef173d38bcb",
   "metadata": {},
   "source": [
    "Now we can join the genre dataframe onto the main book dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "227a267e-18e2-497f-acfd-d90b7162e8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "bookGenreDF = bookDFLanguages.join(genre_df, col('best_book_id') == col('book_id'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f27c37c-00ff-4b05-86e0-ebddcdda79d8",
   "metadata": {},
   "source": [
    "<h3>Books</h3>\n",
    "\n",
    "The books dataset has detailed information about the books themselves. It's similar to the 'works' dataset, but also has things like author, isbn, and a goodreads link."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4c1c5185-bb00-4bb2-997d-5433c02674c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 17:=================================================>      (61 + 8) / 69]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- asin: string (nullable = true)\n",
      " |-- authors: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- author_id: string (nullable = true)\n",
      " |    |    |-- role: string (nullable = true)\n",
      " |-- average_rating: string (nullable = true)\n",
      " |-- book_id: string (nullable = true)\n",
      " |-- country_code: string (nullable = true)\n",
      " |-- description: string (nullable = true)\n",
      " |-- edition_information: string (nullable = true)\n",
      " |-- format: string (nullable = true)\n",
      " |-- image_url: string (nullable = true)\n",
      " |-- is_ebook: string (nullable = true)\n",
      " |-- isbn: string (nullable = true)\n",
      " |-- isbn13: string (nullable = true)\n",
      " |-- kindle_asin: string (nullable = true)\n",
      " |-- language_code: string (nullable = true)\n",
      " |-- link: string (nullable = true)\n",
      " |-- num_pages: string (nullable = true)\n",
      " |-- popular_shelves: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- count: string (nullable = true)\n",
      " |    |    |-- name: string (nullable = true)\n",
      " |-- publication_day: string (nullable = true)\n",
      " |-- publication_month: string (nullable = true)\n",
      " |-- publication_year: string (nullable = true)\n",
      " |-- publisher: string (nullable = true)\n",
      " |-- ratings_count: string (nullable = true)\n",
      " |-- series: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- similar_books: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- text_reviews_count: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- title_without_series: string (nullable = true)\n",
      " |-- url: string (nullable = true)\n",
      " |-- work_id: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "pathB = \"./Datasets/goodreads_books.json\"\n",
    "bookDetailDF = spark.read.json(pathB)\n",
    "bookDetailDF.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d124808-3050-47e7-96e2-92182117b8cb",
   "metadata": {},
   "source": [
    "We don't intend to use all of the information present, so we select just a subset of the fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "324610ae-5b2c-43cc-a7b2-3248c7a3b448",
   "metadata": {},
   "outputs": [],
   "source": [
    "bookDetailDF = bookDetailDF.select(\"book_id\",\\\n",
    "                                   \"work_id\",\\\n",
    "                                   \"isbn\",\\\n",
    "                                   \"isbn13\",\\\n",
    "                                   \"title\",\\\n",
    "                                   \"format\",\\\n",
    "                                   \"url\",\\\n",
    "                                   \"image_url\",\\\n",
    "                                   \"authors\")\n",
    "\n",
    "                                   #\"description\",\\\n",
    "                                   #\"link\",\\"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13cd8cef-b6ad-49e0-b5b5-c74f85dada21",
   "metadata": {},
   "source": [
    "<h3>Author</h3>\n",
    "\n",
    "The books dataset gives a list of authors. We just want the primary author, so we flatten it and just get the primary author's ID. Later in the notebook we'll load the authors dataset and join that in to also get the author's name. We wait to join in the authors dataset until we've filtered the bookDetailDF down to just the rows we plan to keep (i.e. the books that are in the bookGenreDF dataframe)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "30aeaf23-f629-46c0-8dcd-9c1df68c2228",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_author_id(authors_list):\n",
    "    try:\n",
    "        if authors_list and authors_list[0]:\n",
    "            return int(authors_list[0]['author_id'])\n",
    "        else:\n",
    "            return 0\n",
    "    except EOFError:\n",
    "        return 0\n",
    "\n",
    "get_author_id_udf = udf(get_author_id, IntegerType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e5cbc8fd-cdc3-4aca-b73b-bb3e142a18c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "bookDetailDF = bookDetailDF.withColumn('author_id', get_author_id_udf(col('authors'))).drop('authors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "90fbe7ac-026e-4b31-ab2c-45ad1fe2a616",
   "metadata": {},
   "outputs": [],
   "source": [
    "bookDetailDF = bookDetailDF.withColumnRenamed('book_id', 'det_book_id').withColumnRenamed('work_id', 'det_work_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5f642d6e-020b-4825-b948-f975d7921ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "bookDetailDF = bookDetailDF.filter(bookDetailDF.author_id != 0) # CAN REMOVE THIS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60517901-9b38-4fd1-ae23-a5099f3d41dd",
   "metadata": {},
   "source": [
    "<h3>Joining it all</h3>\n",
    "Join it all together: bookGenre has book, genre, and language information; bookDetailDF has book, author, and metadata information; authorDetailDF has author name information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6cb19d81-3abc-4b2c-b672-fee6e304d8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we have works+genres and books+author IDs, join them\n",
    "fullBookDF = bookGenreDF.join(bookDetailDF, bookGenreDF.best_book_id == bookDetailDF.det_book_id)\n",
    "#fullBookDF.count() # 1998"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2d7ed3af-fc02-45ad-91aa-02b8205d77b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# join in author data to get the author name\n",
    "pathA = \"./Datasets/goodreads_book_authors.json\"\n",
    "authorDetailDF = spark.read.json(pathA)\n",
    "#authorDetailDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9c347136-ec5c-4e75-b2ea-32913041dc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "authorDetailDF = authorDetailDF.select(authorDetailDF.author_id, authorDetailDF.name).withColumnRenamed('author_id', 'a_author_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c95f7970-5ff1-4eb6-8045-b131496f4444",
   "metadata": {},
   "outputs": [],
   "source": [
    "fullBookDF = fullBookDF.join(authorDetailDF, fullBookDF.author_id == authorDetailDF.a_author_id).drop('a_author_id')\n",
    "fullBookDF = fullBookDF.withColumnRenamed('best_book_id', 'ITEM_ID')\n",
    "#fullBookDF.count() # 1998"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2d545f-77df-4e27-97d1-6b3fe4dd5b1d",
   "metadata": {},
   "source": [
    "<h3>Write it</h3>\n",
    "\n",
    "By default spark outputs one file per reducer. Because we're running this notebook locally and aren't using a distributed file system, there's no easy to way to coalesce the files back together after the fact. Even though it slows things down, there's enough memory to repartition into a single partition so that the full output is fed to a single file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "01a67dd7-e333-4963-8beb-b314d7918752",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# repartition so we can write it to a single file\n",
    "fullBookDF = fullBookDF.repartition(1)\n",
    "fullBookDF.write.csv(\"personalize_full_book_data.csv\", header=True, mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "867a410b-0829-4767-8cd0-87bbf80498f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ITEM_ID: string (nullable = true)\n",
      " |-- original_publication_day: string (nullable = true)\n",
      " |-- original_publication_month: string (nullable = true)\n",
      " |-- original_publication_year: string (nullable = true)\n",
      " |-- original_title: string (nullable = true)\n",
      " |-- rating_dist: string (nullable = true)\n",
      " |-- ratings_count: string (nullable = true)\n",
      " |-- ratings_sum: string (nullable = true)\n",
      " |-- reviews_count: string (nullable = true)\n",
      " |-- text_reviews_count: string (nullable = true)\n",
      " |-- work_id: string (nullable = true)\n",
      " |-- avg_rating: double (nullable = true)\n",
      " |-- inferred_language_id: string (nullable = true)\n",
      " |-- book_id: string (nullable = true)\n",
      " |-- primary_genre: string (nullable = true)\n",
      " |-- det_book_id: string (nullable = true)\n",
      " |-- det_work_id: string (nullable = true)\n",
      " |-- isbn: string (nullable = true)\n",
      " |-- isbn13: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- format: string (nullable = true)\n",
      " |-- url: string (nullable = true)\n",
      " |-- image_url: string (nullable = true)\n",
      " |-- author_id: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fullBookDF.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c8eb1c-2ab7-4a7b-a2eb-b6f89e212ce4",
   "metadata": {},
   "source": [
    "<h3>Interactions</h3>\n",
    "\n",
    "Now we load the interactions data. We only want to keep user:item interactions that were with an item that we haven't filtered out. We collect the bookIDs into a list, and filter the interactions df on that list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6b56eaee-094f-4c8d-ab4d-2a6bfb34f9aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# get the IDs before we re-partition and write\n",
    "# used later to filter the interactions dataset\n",
    "bookIDs = fullBookDF.select(\"ITEM_ID\").rdd.flatMap(lambda x: x).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "62920db9-cc29-4590-b8bb-840dce1d9340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the bookIDs to truncate / filter down the interactions dataset which is MASSIVE\n",
    "pathI = \"./Datasets/goodreads_interactions.csv\"\n",
    "interactionsDF = spark.read.option(\"header\", True).csv(pathI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1429ab92-340c-4b32-b634-94efcbb142ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- user_id: string (nullable = true)\n",
      " |-- book_id: string (nullable = true)\n",
      " |-- is_read: string (nullable = true)\n",
      " |-- rating: string (nullable = true)\n",
      " |-- is_reviewed: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "interactionsDF.printSchema()\n",
    "#interactionsDF.count() # prefiltered count: 228,648,342"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "23160bf8-dc87-4ace-8b91-5974a6e3af46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1381758"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bookDetailDF = bookDetailDF.filter(bookDetailDF.author_id != 0)\n",
    "interactionsDF = interactionsDF.filter(interactionsDF.is_read == 1) # 112,131,203\n",
    "interactionsDF = interactionsDF.filter(interactionsDF.book_id.isin(bookIDs)) # 1,381,758\n",
    "#interactionsDF.count() # post filtered count 1,381,758"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ebdd7c-0f81-4dca-9bde-31c5fde9b90d",
   "metadata": {},
   "source": [
    "Again, we repartition into a single partition so that we're writing out the contents to a single CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "062f56b1-fb75-4dfd-9aeb-a51903c26764",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "interactionsDF = interactionsDF.repartition(1)\n",
    "interactionsDF.write.csv(\"interactions_data.csv\", header=True, mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8dec202-5d90-43fb-9ae7-b56b42fffa31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87131103-da6b-4807-8f2a-8b6f22c4147c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deaac941-7c99-45ba-a5b2-faf6e4ec9710",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
